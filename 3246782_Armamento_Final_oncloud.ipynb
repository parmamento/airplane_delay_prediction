{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='text-align: center;'> Data Science Technology and Systems </h2>\n",
    "<h3 style='text-align: center;'> Final Assignment: Predicting Airplane Delays </h3>\n",
    "<h3 style='text-align: center;'> Part B â€“ On Cloud </h3>\n",
    "<h4 style='text-align: center;'> Pauline Armamento - u3246782 </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem: Predicting Airplane Delays\n",
    "\n",
    "The goals of this notebook are:\n",
    "- Process and create a dataset from downloaded ZIP files\n",
    "- Exploratory data analysis (EDA)\n",
    "- Establish a baseline model and improve it\n",
    "\n",
    "## Introduction to business scenario\n",
    "You work for a travel booking website that is working to improve the customer experience for flights that were delayed. The company wants to create a feature to let customers know if the flight will be delayed due to weather when the customers are booking the flight to or from the busiest airports for domestic travel in the US. \n",
    "\n",
    "You are tasked with solving part of this problem by leveraging machine learning to identify whether the flight will be delayed due to weather. You have been given access to the a dataset of on-time performance of domestic flights operated by large air carriers. You can use this data to train a machine learning model to predict if the flight is going to be delayed for the busiest airports.\n",
    "\n",
    "### Dataset\n",
    "The provided dataset contains scheduled and actual departure and arrival times reported by certified US air carriers that account for at least 1 percent of domestic scheduled passenger revenues. The data was collected by the Office of Airline Information, Bureau of Transportation Statistics (BTS). The dataset contains date, time, origin, destination, airline, distance, and delay status of flights for flights between 2014 and 2018.\n",
    "The data are in 60 compressed files, where each file contains a CSV for the flight details in a month for the five years (from 2014 - 2018). The data can be downloaded from this [link](https://ucstaff-my.sharepoint.com/:f:/g/personal/ibrahim_radwan_canberra_edu_au/Er0nVreXmihEmtMz5qC5kVIB81-ugSusExPYdcyQTglfLg?e=bNO312). Please download the data files and place them on a relative path. Dataset(s) used in this assignment were compiled by the Office of Airline Information, Bureau of Transportation Statistics (BTS), Airline On-Time Performance Data, available with the following [link](https://www.transtats.bts.gov/Fields.asp?gnoyr_VQ=FGJ). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Prepare the environment \n",
    "\n",
    "Use one of the labs which we have practised on with the Amazon Sagemakers where you perform the following steps:\n",
    "1. Start a lab.\n",
    "2. Create a notebook instance and name it \"oncloudproject\".\n",
    "3. Increase the used memory to 25 GB from the additional configurations.\n",
    "4. Open Jupyter Lab and upload this notebook into it.\n",
    "5. Upload the two combined CVS files (combined_csv_v1.csv and combined_csv_v2.csv), which you created in Part A of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "import warnings, requests, zipfile, io\n",
    "warnings.simplefilter('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "\n",
    "\n",
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "import subprocess\n",
    "from sagemaker import image_uris\n",
    "from sagemaker.image_uris import retrieve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV files into dataframes\n",
    "df1 = pd.read_csv('combined_csv_v1.csv')\n",
    "df2 = pd.read_csv('combined_csv_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in df1\n",
    "print(df1.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing values\n",
    "df1.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Build and evaluate simple models\n",
    "\n",
    "Write code to perform the follwoing steps:\n",
    "1. Split data into training, validation and testing sets (70% - 15% - 15%).\n",
    "2. Use linear learner estimator to build a classifcation model.\n",
    "3. Host the model on another instance\n",
    "4. Perform batch transform to evaluate the model on testing data\n",
    "5. Report the performance metrics that you see better test the model performance \n",
    "\n",
    "Note: You are required to perform the above steps on the two combined datasets separatey and to comments on the difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Split data into training, validation and testing sets (70% - 15% - 15%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train (70%), and then split the remaining 30% into validation (15%) and test (15%)\n",
    "class_column = 'target'  # Target variable for stratified splitting\n",
    "\n",
    "# Split the data into training (70%) and temp (30%)\n",
    "train_data, temp_data = train_test_split(df1, test_size=0.3, random_state=0, stratify=df1[class_column])\n",
    "\n",
    "# Split the temp data into validation (15%) and testing (15%)\n",
    "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=0, stratify=temp_data[class_column])\n",
    "\n",
    "# Print the shapes of the datasets\n",
    "print(\"Training set shape:\", train_data.shape)\n",
    "print(\"Validation set shape:\", val_data.shape)\n",
    "print(\"Testing set shape:\", test_data.shape)\n",
    "\n",
    "# Save these splits to CSV files for uploading to S3\n",
    "train_file = 'train.csv'\n",
    "val_file = 'validation.csv'\n",
    "test_file = 'test.csv'\n",
    "\n",
    "train_data.to_csv(train_file, index=False, header=False)\n",
    "val_data.to_csv(val_file, index=False, header=False)\n",
    "test_data.to_csv(test_file, index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Check Existing Buckets\n",
    "s3_client = boto3.client('s3')\n",
    "response = s3_client.list_buckets()\n",
    "\n",
    "print(\"Existing buckets:\")\n",
    "for bucket in response['Buckets']:\n",
    "    print(f'  {bucket[\"Name\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V1 - Linear Learner Estimator\n",
    "This section presents the code implementation and execution of the Linear Learner Estimator Model, specifically tailored for the combined_csv_v1 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to upload CSV files to S3\n",
    "s3_resource = boto3.Session().resource('s3')\n",
    "\n",
    "def upload_s3_csv(filename, folder, dataframe):\n",
    "    csv_buffer = io.StringIO()\n",
    "    dataframe.to_csv(csv_buffer, header=False, index=False)\n",
    "    s3_resource.Bucket(bucket).Object(os.path.join(prefix, folder, filename)).put(Body=csv_buffer.getvalue())\n",
    "\n",
    "# Define the S3 bucket and prefix\n",
    "bucket='c135321a3429024l7975892t1w377404591872-labbucket-hgx0ormdptdb' # Change according to existing bucket\n",
    "prefix = 'flight-delay-project-data1xgboost'\n",
    "\n",
    "# Upload data to S3\n",
    "upload_s3_csv('train.csv', 'train', train_data)\n",
    "upload_s3_csv('validation.csv', 'validate', val_data)\n",
    "upload_s3_csv('test.csv', 'test', test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Use linear learner estimator to build a classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.amazon.amazon_estimator import RecordSet\n",
    "import boto3\n",
    "\n",
    "# Instantiate the LinearLearner estimator object with 1 ml.m4.xlarge\n",
    "num_classes = len(pd.unique(train_data[class_column]))\n",
    "classifier_estimator = sagemaker.LinearLearner(role=sagemaker.get_execution_role(),\n",
    "                                              instance_count=1,\n",
    "                                              instance_type='ml.m4.xlarge',\n",
    "                                              predictor_type='binary_classifier',\n",
    "                                              binary_classifier_model_selection_criteria = 'cross_entropy_loss')\n",
    "\n",
    "# Create train, validate, and test records\n",
    "train_records = classifier_estimator.record_set(train_data.values[:, 1:].astype(np.float32), train_data.values[:, 0].astype(np.float32), channel='train')\n",
    "val_records = classifier_estimator.record_set(val_data.values[:, 1:].astype(np.float32), val_data.values[:, 0].astype(np.float32), channel='validation')\n",
    "test_records = classifier_estimator.record_set(test_data.values[:, 1:].astype(np.float32), test_data.values[:, 0].astype(np.float32), channel='test')\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "classifier_estimator.fit([train_records, val_records, test_records])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "\n",
    "sagemaker.analytics.TrainingJobAnalytics(classifier_estimator._current_job_name, \n",
    "                                         metric_names = ['test:objective_loss', \n",
    "                                                         'test:binary_f_beta',\n",
    "                                                         'test:precision',\n",
    "                                                         'test:recall']\n",
    "                                        ).dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Host the model on another instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hosting the model\n",
    "\n",
    "import sagemaker\n",
    "\n",
    "# Assume linear_estimator has already been defined and trained\n",
    "predictor = classifier_estimator.deploy(\n",
    "    initial_instance_count=1,  # Number of instances\n",
    "    instance_type='ml.m4.xlarge', \n",
    "    endpoint_name='flight-delay-endpoint'\n",
    ")\n",
    "\n",
    "print(\"Model deployed. Endpoint name:\", predictor.endpoint_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Perform batch transform to evaluate the model on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Transformer\n",
    "\n",
    "def batch_linear_predict(test_data, estimator):\n",
    "    batch_X = test_data.iloc[:,1:];\n",
    "    batch_X_file='batch-in.csv'\n",
    "    upload_s3_csv(batch_X_file, 'batch-in', batch_X)\n",
    "\n",
    "    batch_output = \"s3://{}/{}/batch-out/\".format(bucket,prefix)\n",
    "    batch_input = \"s3://{}/{}/batch-in/{}\".format(bucket,prefix,batch_X_file)\n",
    "\n",
    "    classifier_transformer = estimator.transformer(instance_count=1,\n",
    "                                           instance_type='ml.m4.xlarge',\n",
    "                                           strategy='MultiRecord',\n",
    "                                           assemble_with='Line',\n",
    "                                           output_path=batch_output)\n",
    "\n",
    "    classifier_transformer.transform(data=batch_input,\n",
    "                             data_type='S3Prefix',\n",
    "                             content_type='text/csv',\n",
    "                             split_type='Line')\n",
    "    \n",
    "    classifier_transformer.wait()\n",
    "\n",
    "    s3 = boto3.client('s3')\n",
    "    obj = s3.get_object(Bucket=bucket, Key=\"{}/batch-out/{}\".format(prefix,'batch-in.csv.out'))\n",
    "    target_predicted_df = pd.read_json(io.BytesIO(obj['Body'].read()),orient=\"records\",lines=True)\n",
    "    return test_data.iloc[:,0], target_predicted_df.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels, target_predicted = batch_linear_predict(test_data, classifier_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Report the performance metrics that you see better test the model performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Performance Metrics \n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(test_labels, target_predicted):\n",
    "    matrix = confusion_matrix(test_labels, target_predicted)\n",
    "    df_confusion = pd.DataFrame(matrix)\n",
    "    colormap = sns.color_palette(\"BrBG\", 10)\n",
    "    sns.heatmap(df_confusion, annot=True, fmt='.2f', cbar=None, cmap=colormap)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel(\"True Class\")\n",
    "    plt.xlabel(\"Predicted Class\")\n",
    "    plt.show()\n",
    "    \n",
    "plot_confusion_matrix(test_labels, target_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "\n",
    "def plot_roc(test_labels, target_predicted):\n",
    "    # Calculate confusion matrix components\n",
    "    TN, FP, FN, TP = confusion_matrix(test_labels, target_predicted).ravel()\n",
    "    \n",
    "    # Calculate various metrics\n",
    "    Sensitivity = float(TP) / (TP + FN) * 100 if (TP + FN) > 0 else 0\n",
    "    Specificity = float(TN) / (TN + FP) * 100 if (TN + FP) > 0 else 0\n",
    "    Precision = float(TP) / (TP + FP) * 100 if (TP + FP) > 0 else 0\n",
    "    NPV = float(TN) / (TN + FN) * 100 if (TN + FN) > 0 else 0\n",
    "    FPR = float(FP) / (FP + TN) * 100 if (FP + TN) > 0 else 0\n",
    "    FNR = float(FN) / (TP + FN) * 100 if (TP + FN) > 0 else 0\n",
    "    FDR = float(FP) / (TP + FP) * 100 if (TP + FP) > 0 else 0\n",
    "    ACC = float(TP + TN) / (TP + FP + FN + TN) * 100 if (TP + FP + FN + TN) > 0 else 0\n",
    "\n",
    "    # Print metrics\n",
    "    print(\"Sensitivity or TPR: \", Sensitivity, \"%\") \n",
    "    print(\"Specificity or TNR: \", Specificity, \"%\") \n",
    "    print(\"Precision: \", Precision, \"%\") \n",
    "    print(\"Negative Predictive Value: \", NPV, \"%\") \n",
    "    print(\"False Positive Rate: \", FPR, \"%\")\n",
    "    print(\"False Negative Rate: \", FNR, \"%\") \n",
    "    print(\"False Discovery Rate: \", FDR, \"%\")\n",
    "    print(\"Accuracy: \", ACC, \"%\") \n",
    "\n",
    "    # Calculate AUC\n",
    "    auc_value = roc_auc_score(test_labels, target_predicted)\n",
    "    print(\"Validation AUC:\", auc_value)\n",
    "\n",
    "    # Calculate ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(test_labels, target_predicted)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Plot ROC curve\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    # Create the axis for thresholds\n",
    "    ax2 = plt.gca().twinx()\n",
    "    ax2.plot(fpr, thresholds, markeredgecolor='r', linestyle='dashed', color='r')\n",
    "    ax2.set_ylabel('Threshold', color='r')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc(test_labels, target_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V2 - Linear Learner Estimator\n",
    "This section presents the code implementation and execution of the Linear Learner Estimator Model, specifically tailored for the combined_csv_v2 dataset.\n",
    "\n",
    "We repeat the steps performed previously but we will apply it to df2 that contains combined_csv_v2 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Split data into training, validation and testing sets (70% - 15% - 15%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train (70%), and then split the remaining 30% into validation (15%) and test (15%)\n",
    "class_column = 'target'  # Target variable for stratified splitting\n",
    "\n",
    "# Split the data into training (70%) and temp (30%)\n",
    "train_data, temp_data = train_test_split(df2, test_size=0.3, random_state=0, stratify=df2[class_column])\n",
    "\n",
    "# Split the temp data into validation (15%) and testing (15%)\n",
    "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=0, stratify=temp_data[class_column])\n",
    "\n",
    "# Print the shapes of the datasets\n",
    "print(\"Training set shape:\", train_data.shape)\n",
    "print(\"Validation set shape:\", val_data.shape)\n",
    "print(\"Testing set shape:\", test_data.shape)\n",
    "\n",
    "# Save these splits to CSV files for uploading to S3\n",
    "train_file = 'train.csv'\n",
    "val_file = 'validation.csv'\n",
    "test_file = 'test.csv'\n",
    "\n",
    "train_data.to_csv(train_file, index=False, header=False)\n",
    "val_data.to_csv(val_file, index=False, header=False)\n",
    "test_data.to_csv(test_file, index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "response = s3_client.list_buckets()\n",
    "\n",
    "print(\"Existing buckets:\")\n",
    "for bucket in response['Buckets']:\n",
    "    print(f'  {bucket[\"Name\"]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Use linear learner estimator to build a classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to upload CSV files to S3\n",
    "s3_resource = boto3.Session().resource('s3')\n",
    "\n",
    "def upload_s3_csv(filename, folder, dataframe):\n",
    "    csv_buffer = io.StringIO()\n",
    "    dataframe.to_csv(csv_buffer, header=False, index=False)\n",
    "    s3_resource.Bucket(bucket).Object(os.path.join(prefix, folder, filename)).put(Body=csv_buffer.getvalue())\n",
    "\n",
    "# Define the S3 bucket and prefix\n",
    "bucket='c135321a3429026l8211909t1w07796198217-flightbucket-wiycexlqxuki' #change accordingly\n",
    "prefix = 'flight-delay-project'\n",
    "\n",
    "# Upload data to S3\n",
    "upload_s3_csv('train.csv', 'train', train_data)\n",
    "upload_s3_csv('validation.csv', 'validate', val_data)\n",
    "upload_s3_csv('test.csv', 'test', test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.amazon.amazon_estimator import RecordSet\n",
    "import boto3\n",
    "\n",
    "# Instantiate the LinearLearner estimator object with 1 ml.m4.xlarge\n",
    "num_classes = len(pd.unique(train_data[class_column]))\n",
    "classifier_estimator = sagemaker.LinearLearner(role=sagemaker.get_execution_role(),\n",
    "                                              instance_count=1,\n",
    "                                              instance_type='ml.m4.xlarge',\n",
    "                                              predictor_type='binary_classifier',\n",
    "                                              binary_classifier_model_selection_criteria = 'cross_entropy_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train, validate, and test records\n",
    "train_records = classifier_estimator.record_set(train_data.values[:, 1:].astype(np.float32), train_data.values[:, 0].astype(np.float32), channel='train')\n",
    "val_records = classifier_estimator.record_set(val_data.values[:, 1:].astype(np.float32), val_data.values[:, 0].astype(np.float32), channel='validation')\n",
    "test_records = classifier_estimator.record_set(test_data.values[:, 1:].astype(np.float32), test_data.values[:, 0].astype(np.float32), channel='test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "classifier_estimator.fit([train_records, val_records, test_records])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "\n",
    "sagemaker.analytics.TrainingJobAnalytics(classifier_estimator._current_job_name, \n",
    "                                         metric_names = ['test:objective_loss', \n",
    "                                                         'test:binary_f_beta',\n",
    "                                                         'test:precision',\n",
    "                                                         'test:recall']\n",
    "                                        ).dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Host the model on another instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hosting the model\n",
    "\n",
    "import sagemaker\n",
    "\n",
    "predictor = classifier_estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    endpoint_name='flight-delay-endpoint-v2'  \n",
    ")\n",
    "\n",
    "print(\"Model deployed. Endpoint name:\", predictor.endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Perform batch transform to evaluate the model on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Transformer\n",
    "\n",
    "def batch_linear_predict(test_data, estimator):\n",
    "    batch_X = test_data.iloc[:,1:];\n",
    "    batch_X_file='batch-in.csv'\n",
    "    upload_s3_csv(batch_X_file, 'batch-in', batch_X)\n",
    "\n",
    "    batch_output = \"s3://{}/{}/batch-out/\".format(bucket,prefix)\n",
    "    batch_input = \"s3://{}/{}/batch-in/{}\".format(bucket,prefix,batch_X_file)\n",
    "\n",
    "    classifier_transformer = estimator.transformer(instance_count=1,\n",
    "                                           instance_type='ml.m4.xlarge',\n",
    "                                           strategy='MultiRecord',\n",
    "                                           assemble_with='Line',\n",
    "                                           output_path=batch_output)\n",
    "\n",
    "    classifier_transformer.transform(data=batch_input,\n",
    "                             data_type='S3Prefix',\n",
    "                             content_type='text/csv',\n",
    "                             split_type='Line')\n",
    "    \n",
    "    classifier_transformer.wait()\n",
    "\n",
    "    s3 = boto3.client('s3')\n",
    "    obj = s3.get_object(Bucket=bucket, Key=\"{}/batch-out/{}\".format(prefix,'batch-in.csv.out'))\n",
    "    target_predicted_df = pd.read_json(io.BytesIO(obj['Body'].read()),orient=\"records\",lines=True)\n",
    "    return test_data.iloc[:,0], target_predicted_df.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels, target_predicted = batch_linear_predict(test_data, classifier_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Report the performance metrics that you see better test the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Performance Metrics \n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(test_labels, target_predicted):\n",
    "    matrix = confusion_matrix(test_labels, target_predicted)\n",
    "    df_confusion = pd.DataFrame(matrix)\n",
    "    colormap = sns.color_palette(\"BrBG\", 10)\n",
    "    sns.heatmap(df_confusion, annot=True, fmt='.2f', cbar=None, cmap=colormap)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel(\"True Class\")\n",
    "    plt.xlabel(\"Predicted Class\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(test_labels, target_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "\n",
    "def plot_roc(test_labels, target_predicted):\n",
    "    # Calculate confusion matrix components\n",
    "    TN, FP, FN, TP = confusion_matrix(test_labels, target_predicted).ravel()\n",
    "    \n",
    "    # Calculate various metrics\n",
    "    Sensitivity = float(TP) / (TP + FN) * 100 if (TP + FN) > 0 else 0\n",
    "    Specificity = float(TN) / (TN + FP) * 100 if (TN + FP) > 0 else 0\n",
    "    Precision = float(TP) / (TP + FP) * 100 if (TP + FP) > 0 else 0\n",
    "    NPV = float(TN) / (TN + FN) * 100 if (TN + FN) > 0 else 0\n",
    "    FPR = float(FP) / (FP + TN) * 100 if (FP + TN) > 0 else 0\n",
    "    FNR = float(FN) / (TP + FN) * 100 if (TP + FN) > 0 else 0\n",
    "    FDR = float(FP) / (TP + FP) * 100 if (TP + FP) > 0 else 0\n",
    "    ACC = float(TP + TN) / (TP + FP + FN + TN) * 100 if (TP + FP + FN + TN) > 0 else 0\n",
    "\n",
    "    # Print metrics\n",
    "    print(\"Sensitivity or TPR: \", Sensitivity, \"%\") \n",
    "    print(\"Specificity or TNR: \", Specificity, \"%\") \n",
    "    print(\"Precision: \", Precision, \"%\") \n",
    "    print(\"Negative Predictive Value: \", NPV, \"%\") \n",
    "    print(\"False Positive Rate: \", FPR, \"%\")\n",
    "    print(\"False Negative Rate: \", FNR, \"%\") \n",
    "    print(\"False Discovery Rate: \", FDR, \"%\")\n",
    "    print(\"Accuracy: \", ACC, \"%\") \n",
    "\n",
    "    # Calculate AUC\n",
    "    auc_value = roc_auc_score(test_labels, target_predicted)\n",
    "    print(\"Validation AUC:\", auc_value)\n",
    "\n",
    "    # Calculate ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(test_labels, target_predicted)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Plot ROC curve\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    # Create the axis for thresholds\n",
    "    ax2 = plt.gca().twinx()\n",
    "    ax2.plot(fpr, thresholds, markeredgecolor='r', linestyle='dashed', color='r')\n",
    "    ax2.set_ylabel('Threshold', color='r')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc(test_labels, target_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Estimator Model 1\n",
    "\n",
    "The linear estimator model 1 struggles to accurately predict delays. While it correctly identifies 193,742 instances as \"No Delay\" (true negatives), it misclassifies a significant number of actual delays as \"No Delay.\" Specifically, 51,375 instances of \"Delay\" were incorrectly labeled as \"No Delay\" (false negatives). This high false negative rate undermines the model's reliability for predicting delays, despite its strong performance in identifying \"No Delay\" cases.\n",
    "\n",
    "The linear estimator model 1, while demonstrating strong performance in identifying \"No Delay\" cases with a high specificity of 99.95%, struggles to accurately predict \"Delay\" instances. The model's sensitivity of 0.24% indicates a high false negative rate, meaning it fails to correctly identify a significant portion of actual delays. Additionally, its precision of 56.31% and negative predictive value of 79.04% suggest that while it can correctly identify some delays, it also makes a substantial number of incorrect positive predictions. Overall, the model's performance, as measured by an accuracy of 79.02% and a validation AUC of 0.5009, is limited in its ability to reliably predict delays.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Estimator Model 2\n",
    "\n",
    "Linear estimator model 2, while showing improvement over model 1, still faces challenges in accurately predicting delays. The model correctly identifies 191,858 instances as \"No Delay\" (true negatives). However, it misclassifies a substantial number of actual delays as \"No Delay.\" Specifically, 48,910 instances of \"Delay\" were incorrectly labeled as \"No Delay\" (false negatives). While the model's true positive rate (2,590 correct \"Delay\" predictions) is higher than model 1, the high false negative rate continues to hinder its overall performance in predicting delays.\n",
    "\n",
    "Linear estimator model 2 demonstrates improved performance over model 1, particularly in terms of sensitivity, which has increased to 5.03%. This indicates a higher true positive rate, meaning the model correctly identifies more actual delay instances. However, the model still suffers from a high false negative rate of 94.97%, suggesting that it misses a significant number of true delays. Additionally, while the specificity remains high at 98.98%, the model's precision (56.66%) and negative predictive value (79.69%) suggest that it can still make incorrect positive and negative predictions. Overall, the model's accuracy of 79.26% and validation AUC of 0.5200 indicate a modest improvement over model 1 but still limited predictive power for delay events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Estimator Model Comparison\n",
    "\n",
    "Model 1 struggled to accurately predict delays, despite its high specificity. It had a very low sensitivity, indicating a high false negative rate. This means the model often missed actual delay events.\n",
    "\n",
    "Model 2 shows improvement over Model 1, particularly in terms of sensitivity. It correctly identifies more actual delay instances, reducing the number of false negatives. However, it still suffers from a high false negative rate, suggesting that it misses a significant number of true delays.\n",
    "\n",
    "Model 2 demonstrates significant improvement over Model 1 in accurately identifying delay instances. It exhibits a higher sensitivity, indicating a reduced rate of false negatives. While Model 2 still faces challenges in accurately predicting delays, particularly due to its high false negative rate, it represents a notable step forward in model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Estimator Model Conclusion\n",
    "\n",
    "While both linear estimator models 1 and 2 have shown limitations in accurately predicting delays, particularly in terms of high false negative rates, Model 2 represents a significant improvement. Its increased sensitivity indicates a better ability to identify true delay instances. However, both models still require further refinement and optimization to achieve a more reliable and accurate prediction of delays. Future research should focus on exploring advanced machine learning techniques, incorporating additional relevant features, and fine-tuning model hyperparameters to enhance predictive performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Build and evaluate ensembe models\n",
    "\n",
    "Write code to perform the follwoing steps:\n",
    "1. Split data into training, validation and testing sets (70% - 15% - 15%).\n",
    "2. Use xgboost estimator to build a classifcation model.\n",
    "3. Host the model on another instance\n",
    "4. Perform batch transform to evaluate the model on testing data\n",
    "5. Report the performance metrics that you see better test the model performance \n",
    "6. write down your observation on the difference between the performance of using the simple and ensemble models.\n",
    "Note: You are required to perform the above steps on the two combined datasets separatey."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V1 and V2 - XGBOOST\n",
    "The following sections outline the implementation and execution of the XGBOOST Estimator Model, customized for the datasets combined_csv_v1 (assigned to df1) and combined_csv_v2 (assigned to df2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV files into dataframes\n",
    "df1 = pd.read_csv('combined_csv_v1.csv')\n",
    "df2 = pd.read_csv('combined_csv_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in df1\n",
    "print(df1.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing values\n",
    "df1.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Split data into training, validation and testing sets (70% - 15% - 15%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train (70%), and then split the remaining 30% into validation (15%) and test (15%)\n",
    "class_column = 'target'  # Target variable for stratified splitting\n",
    "\n",
    "# Split the data into training (70%) and temp (30%)\n",
    "train_data, temp_data = train_test_split(df1, test_size=0.3, random_state=0, stratify=df1[class_column]) #change to df2 for combined_csv_v2 \n",
    "\n",
    "# Split the temp data into validation (15%) and testing (15%)\n",
    "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=0, stratify=temp_data[class_column])\n",
    "\n",
    "# Print the shapes of the datasets\n",
    "print(\"Training set shape:\", train_data.shape)\n",
    "print(\"Validation set shape:\", val_data.shape)\n",
    "print(\"Testing set shape:\", test_data.shape)\n",
    "\n",
    "# Save these splits to CSV files for uploading to S3\n",
    "train_file = 'train.csv'\n",
    "val_file = 'validation.csv'\n",
    "test_file = 'test.csv'\n",
    "\n",
    "train_data.to_csv(train_file, index=False, header=False)\n",
    "val_data.to_csv(val_file, index=False, header=False)\n",
    "test_data.to_csv(test_file, index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Check existing buckets\n",
    "s3_client = boto3.client('s3')\n",
    "response = s3_client.list_buckets()\n",
    "\n",
    "print(\"Existing buckets:\")\n",
    "for bucket in response['Buckets']:\n",
    "    print(f'  {bucket[\"Name\"]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to upload CSV files to S3\n",
    "s3_resource = boto3.Session().resource('s3')\n",
    "\n",
    "def upload_s3_csv(filename, folder, dataframe):\n",
    "    csv_buffer = io.StringIO()\n",
    "    dataframe.to_csv(csv_buffer, header=False, index=False)\n",
    "    s3_resource.Bucket(bucket).Object(os.path.join(prefix, folder, filename)).put(Body=csv_buffer.getvalue())\n",
    "\n",
    "# Define the S3 bucket and prefix\n",
    "bucket='c135321a3429022l7975879t1w796437860557-labbucket-zqdijia3ifya'\n",
    "prefix = 'flight-delay-project-data1xgboost'\n",
    "\n",
    "# Upload data to S3\n",
    "upload_s3_csv('train.csv', 'train', train_data)\n",
    "upload_s3_csv('validation.csv', 'validate', val_data)\n",
    "upload_s3_csv('test.csv', 'test', test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Use xgboost estimator to build a classifcation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the XGBoost container\n",
    "container = sagemaker.image_uris.retrieve('xgboost', boto3.Session().region_name, '1.0-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters for the XGBoost model\n",
    "hyperparams = {\n",
    "    \"num_round\": \"42\",\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"objective\": \"binary:logistic\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define S3 output location\n",
    "s3_output_location = f\"s3://{bucket}/{prefix}/output/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the XGBoost model estimator\n",
    "xgb_model = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    sagemaker.get_execution_role(),\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    output_path=s3_output_location,\n",
    "    hyperparameters=hyperparams,\n",
    "    sagemaker_session=sagemaker.Session()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the training input channels\n",
    "train_channel = sagemaker.inputs.TrainingInput(\n",
    "    f\"s3://{bucket}/{prefix}/train/\",\n",
    "    content_type='text/csv'\n",
    ")\n",
    "\n",
    "validate_channel = sagemaker.inputs.TrainingInput(\n",
    "    f\"s3://{bucket}/{prefix}/validate/\",\n",
    "    content_type='text/csv'\n",
    ")\n",
    "\n",
    "# Combine channels into a dictionary\n",
    "data_channels = {'train': train_channel, 'validation': validate_channel}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "xgb_model.fit(inputs=data_channels, logs=False)\n",
    "\n",
    "print('Model training complete and ready for hosting!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Host the model on another instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hosting the model\n",
    "\n",
    "xgb_predictor = xgb_model.deploy(initial_instance_count=1,\n",
    "                serializer = sagemaker.serializers.CSVSerializer(),\n",
    "                instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Perform batch transform to evaluate the model on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Transform\n",
    "\n",
    "batch_X = test_data.iloc[:,1:];\n",
    "batch_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_X_file='batch-in.csv'\n",
    "upload_s3_csv(batch_X_file, 'batch-in', batch_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_output = \"s3://{}/{}/batch-out/\".format(bucket,prefix)\n",
    "batch_input = \"s3://{}/{}/batch-in/{}\".format(bucket,prefix,batch_X_file)\n",
    "\n",
    "xgb_transformer = xgb_model.transformer(instance_count=1,\n",
    "                                       instance_type='ml.m4.xlarge',\n",
    "                                       strategy='MultiRecord',\n",
    "                                       assemble_with='Line',\n",
    "                                       output_path=batch_output)\n",
    "\n",
    "xgb_transformer.transform(data=batch_input,\n",
    "                         data_type='S3Prefix',\n",
    "                         content_type='text/csv',\n",
    "                         split_type='Line')\n",
    "xgb_transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "obj = s3.get_object(Bucket=bucket, Key=\"{}/batch-out/{}\".format(prefix,'batch-in.csv.out'))\n",
    "target_predicted = pd.read_csv(io.BytesIO(obj['Body'].read()),sep=',',names=['class'])\n",
    "target_predicted.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_convert(x):\n",
    "    threshold = 0.65\n",
    "    if x > threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "target_predicted['binary'] = target_predicted['class'].apply(binary_convert)\n",
    "\n",
    "print(target_predicted.head(10))\n",
    "test_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = test_data.iloc[:,0]\n",
    "test_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Report the performance metrics that you see better test the model performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "matrix = confusion_matrix(test_labels, target_predicted['binary'])\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_confusion = pd.DataFrame(matrix, \n",
    "                             index=['Actual No Delay', 'Actual Delay'], \n",
    "                             columns=['Predicted No Delay', 'Predicted Delay'])\n",
    "print(df_confusion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(df_confusion, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Get probabilities for the positive class\n",
    "\n",
    "y_scores = target_predicted['class']\n",
    "\n",
    "# Calculate ROC AUC score\n",
    "roc_auc = roc_auc_score(test_labels, y_scores)\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Calculate ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(test_labels, y_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')  # Diagonal line\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Model 1\n",
    "\n",
    "The XGBoost Model 1, while highly accurate in predicting \"No Delay\" flights (correctly identifying 193,819 instances), struggles significantly with \"Delay\" predictions. The model misclassifies a substantial number of actual delays as \"No Delay,\" resulting in a high false negative rate of 51,439. Although it correctly identifies 61 delay instances (true positives), this number is relatively low compared to the number of missed delays.\n",
    "\n",
    "Model 1 achieves a ROC AUC score of 0.6791. It performs exceptionally well in predicting \"No Delay\" cases, demonstrating high precision, very high recall, and a good F1-score. However, the model struggles with \"Delay\" cases, exhibiting low precision, very low recall, and a very low F1-score. Despite this, the model maintains an overall accuracy of 0.790253."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Model 2\n",
    "\n",
    "XGBoost Model 2, while showing improvement over Model 1, still struggles with accurately predicting \"Delay\" instances. The model correctly identifies 193,130 instances as \"No Delay\" (true negatives). However, it misclassifies a substantial number of actual delays as \"No Delay.\" Specifically, 48,930 instances of \"Delay\" were incorrectly labeled as \"No Delay\" (false negatives). While the model's true positive rate (2,570 correct \"Delay\" predictions) is higher than Model 1, the high false negative rate continues to hinder its overall performance in predicting delays.\n",
    "\n",
    "Model 2 demonstrates a good performance with a ROC AUC score of 0.7308. It excels in predicting \"No Delay\" cases, achieving high precision, very high recall, and a good F1-score. Notably, the model also shows significant improvement in predicting \"Delay\" cases compared to Model 1, with higher precision, recall, and F1-score. This results in an overall accuracy of 0.797672."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Model Comparison\n",
    "\n",
    "Model 2 outperforms Model 1 in terms of overall performance. It achieves a higher ROC AUC score of 0.7308 compared to Model 1's 0.6791, indicating better discrimination between the two classes. Both models exhibit high precision and recall for the \"No Delay\" class, but Model 2 excels in predicting \"Delay\" cases with higher precision (0.783776 vs. 0.753086), recall (0.049903 vs. 0.001184), and F1-score (0.093832 vs. 0.002365). Additionally, Model 2 has a slightly higher overall accuracy of 0.797672 compared to Model 1's 0.790253.\n",
    "\n",
    "Based on the provided metrics, Model 2 appears to be the superior model. It demonstrates better performance in both identifying \"Delay\" cases and overall accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Model Conclusion\n",
    "\n",
    "XGBoost Model 2 outperforms Model 1 in predicting both \"Delay\" and \"No Delay\" cases. While both models excel at identifying \"No Delay\" instances, Model 2 shows significant improvement in predicting \"Delay\" cases, as evidenced by higher precision, recall, and F1-score. This leads to a higher overall accuracy for Model 2.\n",
    "\n",
    "To further improve the model, consider exploring techniques like hyperparameter tuning, feature engineering, and ensemble methods. Additionally, investigating the underlying reasons for the model's limitations in predicting \"Delay\" cases can provide valuable insights for future enhancements.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Conclusion\n",
    "\n",
    "While both linear and XGBoost models have been explored to predict flight delays, the results indicate that both models, particularly the linear models, struggle to accurately predict \"Delay\" cases. This is largely due to the class imbalance in the dataset, where \"No Delay\" cases significantly outnumber \"Delay\" cases.\n",
    "\n",
    "To enhance the predictive performance of the model, several strategies can be employed. Firstly, optimizing the model's hyperparameters through tuning can significantly improve its accuracy. Secondly, addressing the class imbalance issue, where \"Delay\" cases are underrepresented, by techniques like oversampling, undersampling, or class weighting can enhance the model's ability to learn from the minority class. Lastly, exploring different machine learning algorithms and ensemble methods can potentially lead to more robust and accurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
